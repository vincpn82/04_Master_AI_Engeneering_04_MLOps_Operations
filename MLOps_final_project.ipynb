{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d459661",
   "metadata": {},
   "source": [
    "# ğŸ† MLOps per il Monitoraggio della Reputazione Online\n",
    "## MachineInnovators Inc. - Progetto Finale\n",
    "\n",
    "---\n",
    "\n",
    "![MLOps](https://img.shields.io/badge/MLOps-Sentiment%20Analysis-blue)\n",
    "![Python](https://img.shields.io/badge/Python-3.10+-green)\n",
    "![FastAPI](https://img.shields.io/badge/FastAPI-Framework-teal)\n",
    "![HuggingFace](https://img.shields.io/badge/HuggingFace-Transformers-yellow)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Panoramica del Progetto\n",
    "\n",
    "**MachineInnovators Inc.** Ã¨ leader nello sviluppo di applicazioni di machine learning scalabili e pronte per la produzione. Questo progetto implementa una **soluzione end-to-end MLOps** per il monitoraggio automatico della reputazione online attraverso l'analisi del sentiment sui social media.\n",
    "\n",
    "### ğŸ¯ Obiettivi Principali\n",
    "\n",
    "1. **Automazione dell'Analisi del Sentiment**  \n",
    "   Implementare un modello basato su transformer (RoBERTa) per classificare automaticamente i testi in sentiment positivo, neutrale o negativo\n",
    "\n",
    "2. **Monitoraggio Continuo della Reputazione**  \n",
    "   Sistema di monitoraggio continuo per valutare l'andamento del sentiment degli utenti nel tempo\n",
    "\n",
    "3. **Pipeline CI/CD Automatizzata**  \n",
    "   Implementare testing automatico, build e deployment continuo\n",
    "\n",
    "4. **Retraining del Modello**  \n",
    "   Sistema per mantenere alta l'accuratezza predittiva del modello\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Benefici della Soluzione\n",
    "\n",
    "- âœ… **Automazione**: Riduzione degli errori umani e risposta rapida ai feedback\n",
    "- âœ… **ScalabilitÃ **: Gestione di grandi volumi di dati dai social media\n",
    "- âœ… **AffidabilitÃ **: Testing automatico e monitoraggio continuo\n",
    "- âœ… **ManutenibilitÃ **: Pipeline CI/CD per aggiornamenti seamless\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‚ Struttura del Progetto\n",
    "\n",
    "```\n",
    ".\n",
    "â”œâ”€â”€ .github/\n",
    "â”‚   â””â”€â”€ workflows/\n",
    "â”‚       â”œâ”€â”€ ci-cd.yml              # Pipeline CI/CD principale\n",
    "â”‚       â””â”€â”€ monitoring.yml         # Monitoraggio automatico\n",
    "â”œâ”€â”€ app/\n",
    "â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”œâ”€â”€ main.py                    # Applicazione FastAPI\n",
    "â”‚   â”œâ”€â”€ model.py                   # Logica del modello\n",
    "â”‚   â””â”€â”€ schema.py                  # Schemi Pydantic\n",
    "â”œâ”€â”€ tests/\n",
    "â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”œâ”€â”€ test_model.py              # Test del modello\n",
    "â”‚   â””â”€â”€ test_api.py                # Test dell'API\n",
    "â”œâ”€â”€ monitoring/\n",
    "â”‚   â”œâ”€â”€ monitoring.py              # Script monitoraggio\n",
    "â”‚   â””â”€â”€ reports/                   # Report generati\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â””â”€â”€ sample_data.json           # Dati di esempio\n",
    "â”œâ”€â”€ hf_spaces/                     # ğŸš€ HuggingFace Spaces deployment\n",
    "â”‚   â”œâ”€â”€ README.md                  # Card con metadata YAML per Gradio\n",
    "â”‚   â”œâ”€â”€ app.py                     # App Gradio (importa da ../app/)\n",
    "â”‚   â””â”€â”€ requirements.txt           # Dipendenze minimal per HF Spaces\n",
    "â”œâ”€â”€ Dockerfile                     # Container configuration\n",
    "â”œâ”€â”€ requirements.txt               # Dipendenze Python complete\n",
    "â”œâ”€â”€ app.py                         # App Gradio locale (test)\n",
    "â”œâ”€â”€ .gitignore\n",
    "â””â”€â”€ README.md                      # Documentazione completa\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ“… **Data**: Febbraio 2026  \n",
    "ğŸ‘¤ **Autore**: Progetto Finale MLOps - Profession AI Master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe5bcf1",
   "metadata": {},
   "source": [
    "# <a id=\"step1\"></a>\n",
    "# 1ï¸âƒ£ STEP 1: Setup e Introduzione\n",
    "\n",
    "ğŸ’¡ **Nota**: Il codice di setup Ã¨ giÃ  implementato nei file fisici del progetto.\n",
    "\n",
    "## ğŸ¯ Obiettivo\n",
    "\n",
    "Questo step prepara l'ambiente di lavoro per il progetto MLOps. In un progetto reale, qui andresti a installare le dipendenze, configurare l'ambiente e preparare il modello.\n",
    "\n",
    "### ğŸ“š Tecnologie Utilizzate\n",
    "\n",
    "- **Transformers (HuggingFace)**: Libreria per modelli di ML pre-addestrati\n",
    "- **PyTorch**: Framework per deep learning\n",
    "- **FastAPI**: Framework web moderno per costruire API\n",
    "- **Pydantic**: Validazione dati e gestione schemi\n",
    "- **Pytest**: Framework di testing\n",
    "\n",
    "### ğŸ¤– Modello Utilizzato\n",
    "\n",
    "**RoBERTa (Robustly Optimized BERT Pretraining Approach)**\n",
    "\n",
    "- Modello: `cardiffnlp/twitter-roberta-base-sentiment-latest`\n",
    "- Pre-addestrato su ~124M tweet per sentiment analysis\n",
    "- 3 classi: Positive, Negative, Neutral\n",
    "- Accuratezza: ~85-90% su testi in inglese\n",
    "\n",
    "### ğŸ”§ Setup dell'Ambiente\n",
    "\n",
    "1. **Installazione delle Dipendenze**\n",
    "\n",
    "   - Python 3.10+\n",
    "   - Librerie principali: `transformers`, `torch`, `fastapi`, `pydantic`\n",
    "   - Tutte le dipendenze sono elencate in [requirements.txt](requirements.txt)\n",
    "\n",
    "2. **Creazione Ambiente Virtuale**\n",
    "\n",
    "   ```bash\n",
    "   python -m venv venv\n",
    "\n",
    "   source venv/bin/activate  # Windows: venv\\Scripts\\activate   ```\n",
    "   pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd4f691",
   "metadata": {},
   "source": [
    "# <a id=\"step2\"></a>\n",
    "# 2ï¸âƒ£ STEP 2: Implementazione del Modello di Sentiment Analysis\n",
    "\n",
    "ğŸ“ **File di riferimento**: [app/model.py](app/model.py), [app/schema.py](app/schema.py)\n",
    "\n",
    "## ğŸ—ï¸ Architettura del Modello\n",
    "\n",
    "Il modello di sentiment analysis Ã¨ implementato nel file [app/model.py](app/model.py) utilizzando una classe `SentimentAnalyzer`.\n",
    "\n",
    "### ğŸ¨ Design Pattern: Singleton\n",
    "\n",
    "Il modello utilizza il **Singleton pattern** per garantire che:\n",
    "\n",
    "- Una sola istanza del modello sia caricata all'avvio dell'applicazione\n",
    "- Il modello sia riutilizzato per tutte le richieste successive\n",
    "- Si eviti il caricamento ripetuto ad ogni chiamata API\n",
    "\n",
    "### âœ… Vantaggi dell'Approccio\n",
    "\n",
    "1. **Prestazioni**: Singleton evita ri-caricamenti costosi del modello\n",
    "2. **ScalabilitÃ **: Batch processing sfrutta il parallelismo della GPU\n",
    "3. **Validazione**: Pydantic garantisce input corretti e type-safe\n",
    "4. **ManutenibilitÃ **: Codice modulare e ben strutturato\n",
    "5. **Type Safety**: Type hints per migliore supporto IDE\n",
    "\n",
    "### ğŸ§© Componenti Principali\n",
    "\n",
    "**1. Classe SentimentAnalyzer**\n",
    "\n",
    "- **Inizializzazione**: Carica il modello RoBERTa e il tokenizer\n",
    "- **Device Detection**: Seleziona automaticamente GPU (se disponibile) o CPU\n",
    "- **Pipeline HuggingFace**: Incapsula tokenization, inferenza e post-processing\n",
    "\n",
    "**2. Metodi Implementati**\n",
    "\n",
    "- `get_info()` â†’ Informazioni sul modello\n",
    "  - Restituisce: nome modello, device, max_length, num_labels\n",
    "\n",
    "- `predict(text: str)` â†’ Predizione singola\n",
    "  - Input: Un singolo testo\n",
    "  - Output: `{text, sentiment, confidence}`\n",
    "\n",
    "- `predict_batch(texts: List[str])` â†’ Predizione batch\n",
    "  - Input: Lista di testi (fino a 100)\n",
    "  - Output: Lista di risultati\n",
    "  - **Performance**: 10-16x piÃ¹ veloce grazie al parallelismo GPU\n",
    "\n",
    "### ğŸ“Š Schemi di Validazione\n",
    "\n",
    "Il file [app/schema.py](app/schema.py) definisce gli schemi Pydantic per:\n",
    "\n",
    "- **SingleTextInput**: Validazione input singolo (min 1, max 512 caratteri)\n",
    "- **BatchTextInput**: Validazione batch (min 1, max 100 testi)\n",
    "- **SentimentResult**: Formato output standardizzato\n",
    "\n",
    "- **BatchSentimentOutput**: Output per predizioni batch- **HealthResponse**: Risposta health check endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4711a1de",
   "metadata": {},
   "source": [
    "# <a id=\"step3\"></a>\n",
    "# 3ï¸âƒ£ STEP 3: Creazione Struttura Progetto\n",
    "\n",
    "## ğŸ“¦ Repository GitHub del Progetto\n",
    "\n",
    "A partire da questo step, tutti i file del progetto (configurazione, codice sorgente, test, CI/CD workflows, ecc.) sono stati creati fisicamente e sono disponibili nel repository GitHub:\n",
    "\n",
    "**ğŸ”— Repository:** [https://github.com/vincpn82/04_Master_AI_Engeneering_04_MLOps_Operations.git](https://github.com/vincpn82/04_Master_AI_Engeneering_04_MLOps_Operations.git)\n",
    "\n",
    "### ğŸ“‚ Struttura del Progetto Completo\n",
    "\n",
    "Il progetto contiene la seguente struttura:\n",
    "\n",
    "```\n",
    ".\n",
    "â”œâ”€â”€ .github/\n",
    "â”‚   â””â”€â”€ workflows/\n",
    "â”‚       â”œâ”€â”€ ci-cd.yml              # Pipeline CI/CD principale\n",
    "â”‚       â””â”€â”€ monitoring.yml         # Monitoraggio automatico\n",
    "â”œâ”€â”€ app/\n",
    "â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”œâ”€â”€ main.py                    # Applicazione FastAPI\n",
    "â”‚   â”œâ”€â”€ model.py                   # Logica del modello\n",
    "â”‚   â””â”€â”€ schema.py                  # Schemi Pydantic\n",
    "â”œâ”€â”€ tests/\n",
    "â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”œâ”€â”€ test_model.py              # Test del modello\n",
    "â”‚   â””â”€â”€ test_api.py                # Test dell'API\n",
    "â”œâ”€â”€ monitoring/\n",
    "â”‚   â”œâ”€â”€ monitoring.py              # Script monitoraggio\n",
    "â”‚   â””â”€â”€ reports/                   # Report generati\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â””â”€â”€ sample_data.json           # Dati di esempio\n",
    "â”œâ”€â”€ hf_spaces/                     # ğŸš€ HuggingFace Spaces deployment\n",
    "â”‚   â”œâ”€â”€ README.md                  # Card con metadata YAML per Gradio\n",
    "â”‚   â”œâ”€â”€ app.py                     # App Gradio (importa da ../app/)\n",
    "â”‚   â””â”€â”€ requirements.txt           # Dipendenze minimal per HF Spaces\n",
    "â”œâ”€â”€ Dockerfile                     # Container configuration\n",
    "â”œâ”€â”€ .dockerignore                  # File esclusi dal build Docker\n",
    "â”œâ”€â”€ requirements.txt               # Dipendenze Python complete\n",
    "â”œâ”€â”€ app.py                         # App Gradio locale (test)\n",
    "â”œâ”€â”€ .gitignore                     # File esclusi da Git\n",
    "â””â”€â”€ README.md                      # Documentazione completa\n",
    "```\n",
    "\n",
    "### ğŸš€ Come utilizzare il repository\n",
    "\n",
    "Per clonare e usare il progetto:\n",
    "\n",
    "```bash\n",
    "# Clone del repository\n",
    "git clone https://github.com/vincpn82/04_Master_AI_Engeneering_04_MLOps_Operations.git\n",
    "cd 04_Master_AI_Engeneering_04_MLOps_Operations\n",
    "\n",
    "# Crea ambiente virtuale e installa dipendenze\n",
    "python -m venv venv\n",
    "source venv/bin/activate  # Su Windows: venv\\Scripts\\activate\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Avvia l'API (dalla radice del progetto)\n",
    "uvicorn app.main:app --reload\n",
    "```\n",
    "\n",
    "### ğŸ“š Documentazione\n",
    "\n",
    "Tutti i dettagli sull'installazione, configurazione, utilizzo e deployment sono disponibili nel file [README.md](https://github.com/vincpn82/04_Master_AI_Engeneering_04_MLOps_Operations/blob/main/README.md) del repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2890f0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4ï¸âƒ£ STEP 4: API REST con FastAPI\n",
    "\n",
    "## ğŸš€ Avvio del Server\n",
    "\n",
    "Per avviare il server FastAPI, apri un terminale nella cartella del progetto ed esegui:\n",
    "\n",
    "```bash\n",
    "uvicorn app.main:app --reload\n",
    "```\n",
    "\n",
    "Il server sarÃ  disponibile su:\n",
    "- ğŸŒ **API**: `http://localhost:8000`\n",
    "- ğŸ“ **Documentazione Swagger**: `http://localhost:8000/docs`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e027e5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5ï¸âƒ£ STEP 5: Testing con Pytest\n",
    "\n",
    "In MLOps, il testing Ã¨ fondamentale per garantire che il modello e l'API funzionino correttamente in produzione. Implementeremo test automatizzati utilizzando **pytest**.\n",
    "\n",
    "## ğŸ“¦ Struttura dei Test\n",
    "\n",
    "Il progetto include due tipi di test:\n",
    "\n",
    "- **test_model.py**: Test della logica del modello di ML\n",
    "- **test_api.py**: Test degli endpoint FastAPI\n",
    "\n",
    "**ğŸ”— File dei Test:**\n",
    "- [tests/test_model.py](https://github.com/vincpn82/04_Master_AI_Engeneering_04_MLOps_Operations/blob/main/tests/test_model.py)\n",
    "- [tests/test_api.py](https://github.com/vincpn82/04_Master_AI_Engeneering_04_MLOps_Operations/blob/main/tests/test_api.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7970b",
   "metadata": {},
   "source": [
    "## ğŸš€ Come Eseguire i Test\n",
    "\n",
    "Prima di eseguire i test, assicurati di avere pytest installato:\n",
    "\n",
    "```bash\n",
    "pip install pytest\n",
    "```\n",
    "\n",
    "### ğŸ“‹ Comandi per Eseguire i Test\n",
    "\n",
    "```bash\n",
    "# Esegui tutti i test con output dettagliato\n",
    "pytest tests/ -v\n",
    "\n",
    "# Esegui solo i test del modello\n",
    "pytest tests/test_model.py -v\n",
    "\n",
    "# Esegui solo i test dell'API\n",
    "pytest tests/test_api.py -v\n",
    "\n",
    "# Esegui un test specifico per nome\n",
    "pytest tests/ -k \"test_predict_positive\" -v\n",
    "\n",
    "# Esegui i test con coverage report\n",
    "pytest tests/ --cov=app --cov-report=term-missing\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e53d3c4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6ï¸âƒ£ STEP 6: Containerizzazione con Docker\n",
    "\n",
    "## ğŸ“¦ Il Dockerfile del Progetto\n",
    "\n",
    "Il file [Dockerfile](Dockerfile) definisce come costruire l'immagine Docker del nostro servizio di sentiment analysis. L'immagine contiene tutto il necessario per eseguire l'applicazione FastAPI in modo isolato e riproducibile.\n",
    "\n",
    "**Caratteristiche principali:**\n",
    "- Immagine base: `python:3.10-slim` (versione leggera)\n",
    "- Ottimizzazione: `--no-cache-dir` riduce la dimensione finale dell'immagine\n",
    "- Porta esposta: `8000` per FastAPI\n",
    "\n",
    "ğŸ“ **File di riferimento**: [Dockerfile](Dockerfile)\n",
    "\n",
    "## ğŸš€ Comandi Docker\n",
    "\n",
    "### Build dell'Immagine\n",
    "\n",
    "```bash\n",
    "# Build con tag \"latest\"\n",
    "docker build -t sentiment-analysis:latest .\n",
    "\n",
    "# Build con tag specifico (es: versione)\n",
    "docker build -t sentiment-analysis:v1.0 .\n",
    "```\n",
    "\n",
    "### Run del Container\n",
    "\n",
    "```bash\n",
    "# Esegui in background (-d = detached)\n",
    "docker run -d -p 8000:8000 --name sentiment-api sentiment-analysis:latest\n",
    "\n",
    "# Esegui con logs visibili (per debug)\n",
    "docker run -p 8000:8000 --name sentiment-api sentiment-analysis:latest\n",
    "```\n",
    "\n",
    "**Spiegazione parametri:**\n",
    "- `-d` â†’ Esegue in background\n",
    "- `-p 8000:8000` â†’ Mappa porta container (8000) su porta host (8000)\n",
    "- `--name sentiment-api` â†’ Nome del container\n",
    "\n",
    "### Gestione Container\n",
    "\n",
    "```bash\n",
    "# Verifica container attivi\n",
    "docker ps\n",
    "\n",
    "# Visualizza tutti i container (anche fermati)\n",
    "docker ps -a\n",
    "\n",
    "# Visualizza logs del container\n",
    "docker logs sentiment-api\n",
    "\n",
    "# Segui i logs in real-time\n",
    "docker logs -f sentiment-api\n",
    "\n",
    "# Stop del container\n",
    "docker stop sentiment-api\n",
    "\n",
    "# Riavvia container\n",
    "docker start sentiment-api\n",
    "\n",
    "# Rimuovi container\n",
    "docker rm sentiment-api\n",
    "\n",
    "# Rimuovi container forzatamente (anche se running)\n",
    "docker rm -f sentiment-api\n",
    "```\n",
    "\n",
    "### Test dell'API nel Container\n",
    "\n",
    "```bash\n",
    "# Health check\n",
    "curl http://localhost:8000/health\n",
    "\n",
    "# Predizione singola\n",
    "curl -X POST \"http://localhost:8000/predict\" \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"text\":\"This product is amazing!\"}'\n",
    "\n",
    "# Accedi alla documentazione Swagger\n",
    "# Apri: http://localhost:8000/docs\n",
    "```\n",
    "\n",
    "## ğŸŒ Docker Hub - Pubblicazione Immagine\n",
    "\n",
    "Docker Hub permette di distribuire l'immagine su qualsiasi sistema.\n",
    "\n",
    "### Setup\n",
    "\n",
    "```bash\n",
    "# Login a Docker Hub\n",
    "docker login\n",
    "\n",
    "# Inserisci username e password quando richiesto\n",
    "```\n",
    "\n",
    "### Tag e Push\n",
    "\n",
    "```bash\n",
    "# Tag l'immagine con il tuo username Docker Hub\n",
    "docker tag sentiment-analysis:latest tuousername/sentiment-analysis:latest\n",
    "\n",
    "# (Opzionale) Aggiungi anche un tag versione\n",
    "docker tag sentiment-analysis:latest tuousername/sentiment-analysis:v1.0\n",
    "\n",
    "# Push su Docker Hub\n",
    "docker push tuousername/sentiment-analysis:latest\n",
    "docker push tuousername/sentiment-analysis:v1.0\n",
    "```\n",
    "\n",
    "### Pull da Altro Sistema\n",
    "\n",
    "```bash\n",
    "# Scarica l'immagine da Docker Hub\n",
    "docker pull tuousername/sentiment-analysis:latest\n",
    "\n",
    "# Esegui direttamente\n",
    "docker run -d -p 8000:8000 tuousername/sentiment-analysis:latest\n",
    "```\n",
    "\n",
    "## ğŸ’¡ Tips & Best Practices\n",
    "\n",
    "1. **Layer Caching**: Docker riutilizza i layer non modificati â†’ build successive molto piÃ¹ veloci\n",
    "2. **.dockerignore**: Esclude file non necessari (es: `.git`, `__pycache__`, `venv`)\n",
    "3. **Multi-stage Build**: (Avanzato) Riduce ulteriormente dimensioni separando build e runtime\n",
    "4. **Security**: Non includere mai secrets o credenziali nell'immagine\n",
    "5. **Health Check**: Docker supporta health check nativi per orchestrazione\n",
    "\n",
    "ğŸ“ **File di riferimento**: [Dockerfile](Dockerfile), [.dockerignore](.dockerignore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba779ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7ï¸âƒ£ STEP 7: CI/CD con GitHub Actions\n",
    "\n",
    "## ğŸ”„ Continuous Integration / Continuous Deployment\n",
    "\n",
    "Il CI/CD automatizza testing, validazione e deployment ad ogni modifica del codice. In MLOps Ã¨ fondamentale per:\n",
    "\n",
    "- **Quality Assurance**: Test automatici prevengono regressioni\n",
    "- **Model Validation**: Verifica delle performance su dataset reale\n",
    "- **Deployment Rapido**: Da commit a produzione in minuti\n",
    "- **TracciabilitÃ **: Ogni deploy Ã¨ linkato a uno specifico commit\n",
    "\n",
    "Il file [.github/workflows/ci-cd.yml](.github/workflows/ci-cd.yml) definisce la pipeline completa.\n",
    "\n",
    "## ğŸ¯ Trigger della Pipeline\n",
    "\n",
    "La pipeline si attiva automaticamente ad ogni push sul branch `main`:\n",
    "\n",
    "```yaml\n",
    "on:\n",
    "  push:\n",
    "    branches: [ main ]\n",
    "```\n",
    "\n",
    "## ğŸ“‹ Struttura della Pipeline\n",
    "\n",
    "La pipeline Ã¨ composta da **3 job sequenziali**:\n",
    "\n",
    "### Job 1: test (Run Tests) ğŸ§ª\n",
    "\n",
    "**Obiettivo**: Verificare che il codice funzioni correttamente prima del deploy\n",
    "\n",
    "**Configurazione:**\n",
    "- `runs-on: ubuntu-latest`\n",
    "- Nessuna dipendenza da altri job\n",
    "\n",
    "**Steps:**\n",
    "1. **Checkout code** (`actions/checkout@v3`) - Scarica il codice dal repository\n",
    "2. **Set up Python** (`actions/setup-python@v4`) - Configura Python 3.10\n",
    "3. **Cache pip packages** (`actions/cache@v3`) - Riutilizza dipendenze giÃ  scaricate\n",
    "   - Path: `~/.cache/pip`\n",
    "   - Key: `${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}`\n",
    "4. **Install dependencies** - Esegue:\n",
    "   ```bash\n",
    "   python -m pip install --upgrade pip\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "5. **Run model tests** - Esegue `pytest tests/test_model.py -v`\n",
    "6. **Run API tests** - Esegue `pytest tests/test_api.py -v`\n",
    "\n",
    "**Condizione di successo**: Tutti i test devono passare (exit code 0)\n",
    "\n",
    "### Job 2: model-validation (Model Validation) ğŸ“Š\n",
    "\n",
    "**Obiettivo**: Validare le performance del modello su un dataset di test reale\n",
    "\n",
    "**Configurazione:**\n",
    "- `runs-on: ubuntu-latest`\n",
    "- `needs: test` - Si avvia solo se il job `test` Ã¨ completato con successo\n",
    "\n",
    "**Steps:**\n",
    "1. **Checkout code** (`actions/checkout@v3`) - Scarica il codice\n",
    "2. **Set up Python** (`actions/setup-python@v4`) - Configura Python 3.10\n",
    "3. **Cache pip packages** (`actions/cache@v3`) - Stesso meccanismo del Job 1\n",
    "4. **Install dependencies** - Esegue:\n",
    "   ```bash\n",
    "   python -m pip install --upgrade pip\n",
    "   pip install -r requirements.txt\n",
    "   pip install datasets scikit-learn  # Per il monitoraggio\n",
    "   ```\n",
    "5. **Run model validation** - Esegue `python monitoring/monitoring.py`\n",
    "6. **Upload validation reports** (`actions/upload-artifact@v3`)\n",
    "   - Nome artifact: `validation-reports`\n",
    "   - Path: `monitoring/reports/`\n",
    "   - Retention: 30 giorni\n",
    "   - Condizione: `if: always()` (carica anche se il job fallisce)\n",
    "\n",
    "**Cosa valida:**\n",
    "- Carica il modello RoBERTa\n",
    "- Testa su 1200 campioni del dataset **TweetEval**\n",
    "- Calcola metriche: Accuracy, Precision, Recall, F1-Score\n",
    "- Genera confusion matrix e report dettagliati\n",
    "- **Alert se accuracy < 70%**\n",
    "\n",
    "**Report generati** (scaricabili da GitHub Actions â†’ Artifacts):\n",
    "- `metrics_{timestamp}.csv` - Metriche numeriche\n",
    "- `confusion_matrix_{timestamp}.png` - Visualizzazione\n",
    "- `predictions_{timestamp}.csv` - Predizioni dettagliate\n",
    "- `classification_report_{timestamp}.txt` - Report completo\n",
    "\n",
    "### Job 3: deploy-to-huggingface (Deploy to HuggingFace Spaces) ğŸ¤—\n",
    "\n",
    "**Obiettivo**: Deploy automatico dell'app Gradio su HuggingFace Spaces\n",
    "\n",
    "**Configurazione:**\n",
    "- `runs-on: ubuntu-latest`\n",
    "- `needs: [test, model-validation]` - Si avvia solo se **entrambi** i job precedenti sono completati con successo\n",
    "- `if: github.event_name == 'push' && github.ref == 'refs/heads/main'` - Solo per push su `main`\n",
    "\n",
    "**Steps:**\n",
    "1. **Checkout code** (`actions/checkout@v3`) - Scarica il codice\n",
    "2. **Push to HuggingFace Space** - Esegue:\n",
    "   ```bash\n",
    "   git config --global user.email \"ci@machineinnovators.com\"\n",
    "   git config --global user.name \"CI Bot\"\n",
    "   git remote add hf https://huggingface.co/spaces/${{ secrets.HF_SPACE_NAME }}\n",
    "   git push hf main --force\n",
    "   ```\n",
    "\n",
    "**Secrets richiesti** (da configurare in GitHub â†’ Settings â†’ Secrets):\n",
    "- `HF_TOKEN`: Token di autenticazione HuggingFace (con permesso write)\n",
    "- `HF_SPACE_NAME`: Nome dello Space (formato: `username/space-name`)\n",
    "\n",
    "ğŸ’¡ **Nota**: Questo job Ã¨ opzionale. Per disabilitarlo, commentare l'intero blocco `deploy-to-huggingface` nel file [.github/workflows/ci-cd.yml](.github/workflows/ci-cd.yml).\n",
    "\n",
    "## âœ… Vantaggi del CI/CD in MLOps\n",
    "\n",
    "1. **QualitÃ  del Codice**\n",
    "   - Test automatici ad ogni commit\n",
    "   - Validazione performance del modello su dataset reale\n",
    "   - Impossibile deployare codice che rompe i test o degrada il modello\n",
    "   - Coverage tracking nel tempo\n",
    "\n",
    "2. **VelocitÃ  di Deployment**\n",
    "   - Da commit a produzione in ~5-10 minuti\n",
    "   - Zero intervento manuale\n",
    "   - Deploy ripetibili e consistenti\n",
    "\n",
    "3. **TracciabilitÃ  Completa**\n",
    "   - Ogni deploy linkato a commit SHA\n",
    "   - Log completi di ogni esecuzione\n",
    "   - Audit trail per compliance\n",
    "   - Artifacts di validazione salvati per 30 giorni\n",
    "\n",
    "4. **Feedback Immediato**\n",
    "   - Notifiche automatiche se pipeline fallisce\n",
    "   - Report di validazione disponibili immediatamente\n",
    "   - Metrics tracking nel tempo\n",
    "\n",
    "## ğŸ“Š Workflow Visuale\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Git Push   â”‚\n",
    "â”‚   (main)    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\n",
    "       â”‚\n",
    "       â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  JOB 1: test (Run Tests)             â”‚\n",
    "â”‚  - Checkout code                     â”‚\n",
    "â”‚  - Setup Python 3.10                 â”‚\n",
    "â”‚  - Cache pip packages                â”‚\n",
    "â”‚  - Install dependencies              â”‚\n",
    "â”‚  - pytest tests/test_model.py -v     â”‚\n",
    "â”‚  - pytest tests/test_api.py -v       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "       â”‚\n",
    "       â”œâ”€â”€â”€ âœ… PASS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "       â”‚                                  â”‚\n",
    "       â”‚                                  â–¼\n",
    "       â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "       â”‚                 â”‚ JOB 2: model-validation            â”‚\n",
    "       â”‚                 â”‚ needs: [test]                      â”‚\n",
    "       â”‚                 â”‚ - Checkout code                    â”‚\n",
    "       â”‚                 â”‚ - Setup Python 3.10                â”‚\n",
    "       â”‚                 â”‚ - Cache pip packages               â”‚\n",
    "       â”‚                 â”‚ - Install deps + datasets + sklearnâ”‚\n",
    "       â”‚                 â”‚ - python monitoring/monitoring.py  â”‚\n",
    "       â”‚                 â”‚ - Upload artifacts (30 days)       â”‚\n",
    "       â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "       â”‚                           â”‚\n",
    "       â”‚                           â”œâ”€â”€â”€ âœ… PASS (accuracy >= 70%) â”€â”€â”€â”€â”\n",
    "       â”‚                           â”‚                                  â”‚\n",
    "       â”‚                           â”‚                                  â–¼\n",
    "       â”‚                           â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "       â”‚                           â”‚              â”‚ JOB 3: deploy-to-huggingface   â”‚\n",
    "       â”‚                           â”‚              â”‚ needs: [test, model-validation]â”‚\n",
    "       â”‚                           â”‚              â”‚ if: push to main               â”‚\n",
    "       â”‚                           â”‚              â”‚ - Checkout code                â”‚\n",
    "       â”‚                           â”‚              â”‚ - Push to HF Spaces            â”‚\n",
    "       â”‚                           â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "       â”‚                           â”‚\n",
    "       â”‚                           â””â”€â”€â”€ âŒ FAIL â†’ Block Deploy\n",
    "       â”‚\n",
    "       â””â”€â”€â”€ âŒ FAIL â†’ Block Pipeline\n",
    "```\n",
    "\n",
    "## ğŸ”” Monitoraggio Pipeline\n",
    "\n",
    "**Dove vedere l'esecuzione:**\n",
    "- GitHub â†’ Repository â†’ Tab `Actions`\n",
    "- Ogni esecuzione mostra:\n",
    "  - Status (âœ… Success / âŒ Failed / ğŸŸ¡ In Progress)\n",
    "  - Durata totale di ogni job\n",
    "  - Log dettagliati di ogni step\n",
    "  - Artifacts generati (validation reports disponibili per 30 giorni)\n",
    "\n",
    "**Notifiche:**\n",
    "- Email automatica se pipeline fallisce\n",
    "- Integration con Slack/Discord (opzionale, configurabile)\n",
    "\n",
    "**Download Artifacts:**\n",
    "- GitHub Actions â†’ Workflow run â†’ Scroll down â†’ Artifacts section\n",
    "- Download `validation-reports.zip` contenente tutti i report generati\n",
    "\n",
    "ğŸ“ **File di riferimento**: [.github/workflows/ci-cd.yml](.github/workflows/ci-cd.yml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d104f957",
   "metadata": {},
   "source": [
    "# 8ï¸âƒ£ STEP 8: Model Monitoring\n",
    "\n",
    "## ğŸ” Lo Script monitoring.py\n",
    "\n",
    "Il file [monitoring/monitoring.py](monitoring/monitoring.py) implementa il sistema di monitoraggio del modello attraverso due funzioni principali:\n",
    "\n",
    "### Funzioni Principali\n",
    "\n",
    "**`load_test_data()`**\n",
    "- Carica il dataset **TweetEval** da HuggingFace (`tweet_eval/sentiment`)\n",
    "- Utilizza lo split `test` (dati mai visti dal modello durante il training)\n",
    "- Converte le label numeriche in formato testuale: `0` â†’ `negative`, `1` â†’ `neutral`, `2` â†’ `positive`\n",
    "\n",
    "**`evaluate_model()`**\n",
    "- Carica il modello RoBERTa di sentiment analysis\n",
    "- Esegue predizioni su **1200 campioni** del test set\n",
    "- Calccula 4 metriche di performance: Accuracy, Precision, Recall, F1-Score\n",
    "- Genera 4 tipologie di report\n",
    "- Controlla se l'accuracy scende sotto la soglia critica (70%)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Report Generati\n",
    "\n",
    "Ad ogni esecuzione, lo script crea 4 file nella cartella `monitoring/reports/`:\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Š 1. `metrics_{timestamp}.csv`\n",
    "\n",
    "**Contenuto**: Metriche aggregate in formato CSV\n",
    "\n",
    "**Colonne**: `timestamp`, `accuracy`, `precision`, `recall`, `f1_score`, `num_samples`\n",
    "\n",
    "**Utilizzo**: Tracking delle performance nel tempo, creazione di grafici di trend\n",
    "\n",
    "<br>\n",
    "\n",
    "> ğŸ“‹ **ESEMPIO DI OUTPUT**\n",
    "> \n",
    "> ```csv\n",
    "> timestamp,accuracy,precision,recall,f1_score,num_samples\n",
    "> 20260222_143527,0.8420,0.8385,0.8420,0.8391,500\n",
    "> ```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ˆ 2. `confusion_matrix_{timestamp}.png`\n",
    "\n",
    "**Contenuto**: Visualizzazione grafica della confusion matrix 3x3\n",
    "\n",
    "Heatmap con scala di colori blu che mostra:\n",
    "- **Diagonale principale**: Predizioni corrette\n",
    "- **Celle fuori diagonale**: Errori di classificazione\n",
    "\n",
    "Pattern comuni: Neutral spesso confuso con Positive o Negative (sentiment ambiguo)\n",
    "\n",
    "<br>\n",
    "\n",
    "> ğŸ“Š **ESEMPIO DI INTERPRETAZIONE**\n",
    "> \n",
    "> ```\n",
    ">               Predicted\n",
    ">            Neg  Neu  Pos\n",
    "> True Neg  [140   15   12]  â† 140 corrette, 27 errori\n",
    ">      Neu  [ 18  135   13]\n",
    ">      Pos  [ 10   12  145]\n",
    "> ```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ 3. `predictions_{timestamp}.csv`\n",
    "\n",
    "**Contenuto**: Dettaglio di ogni singola predizione\n",
    "\n",
    "**Colonne**: `text`, `true_label`, `predicted_label`\n",
    "\n",
    "**Utilizzo**: Analisi qualitativa degli errori, identificazione di pattern di testi problematici\n",
    "\n",
    "<br>\n",
    "\n",
    "> ğŸ“‹ **ESEMPIO DI OUTPUT**\n",
    "> \n",
    "> ```csv\n",
    "> text,true_label,predicted_label\n",
    "> \"This product is amazing!\",positive,positive\n",
    "> \"I hate this service\",negative,negative\n",
    "> \"It's okay\",neutral,neutral\n",
    "> ```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“„ 4. `classification_report_{timestamp}.txt`\n",
    "\n",
    "**Contenuto**: Report testuale dettagliato con metriche per ogni classe\n",
    "\n",
    "Include precision, recall, f1-score e support per ogni sentiment, piÃ¹ le medie macro e weighted\n",
    "\n",
    "<br>\n",
    "\n",
    "> ğŸ“‹ **ESEMPIO DI OUTPUT**\n",
    "> \n",
    "> ```\n",
    ">               precision    recall  f1-score   support\n",
    "> \n",
    ">     negative       0.85      0.83      0.84       167\n",
    ">      neutral       0.78      0.81      0.79       166\n",
    ">     positive       0.88      0.86      0.87       167\n",
    "> \n",
    ">     accuracy                           0.84       500\n",
    ">    macro avg       0.84      0.83      0.83       500\n",
    "> weighted avg       0.84      0.84      0.84       500\n",
    "> ```\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "## ğŸš¨ Alert System\n",
    "\n",
    "### âš ï¸ Quando Scatta l'Alert\n",
    "\n",
    "**Threshold critica**: Accuracy < **70%**\n",
    "\n",
    "Quando l'accuracy scende sotto questa soglia, il sistema stampa un messaggio di alert e raccomanda di considerare il retraining del modello.\n",
    "\n",
    "<br>\n",
    "\n",
    "> ğŸ”´ **MESSAGGIO DI ALERT**\n",
    "> \n",
    "> ```\n",
    "> âš ï¸  ALERT: L'accuracy (0.6850) Ã¨ sotto la soglia (0.69)!\n",
    ">     Considera il retraining del modello.\n",
    "> ```\n",
    "\n",
    "<br>\n",
    "\n",
    "### ğŸ”§ Azioni Correttive\n",
    "\n",
    "Quando scatta l'alert:\n",
    "\n",
    "**1ï¸âƒ£ Analisi Immediata**\n",
    "- Scarica e analizza i 4 report generati\n",
    "- Controlla la confusion matrix: quali classi sono piÃ¹ problematiche?\n",
    "- Verifica se ci sono problemi di data quality nel test set\n",
    "\n",
    "**2ï¸âƒ£ Investigazione**\n",
    "- Confronta con i report precedenti: degrado improvviso o progressivo?\n",
    "- Verifica se ci sono stati cambiamenti nei dati di input\n",
    "- Valuta se c'Ã¨ concept drift (il significato di \"positive/negative\" Ã¨ cambiato?)\n",
    "\n",
    "**3ï¸âƒ£ Decisione**\n",
    "- Se degrado temporaneo: Monitora la prossima esecuzione\n",
    "- Se degrado persistente: Pianifica retraining del modello\n",
    "- Se degrado critico (accuracy < 60%): Considera hotfix o rollback\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Come Eseguire il Monitoraggio\n",
    "\n",
    "### ğŸ’» Esecuzione Manuale\n",
    "\n",
    "Dalla root del progetto, esegui:\n",
    "\n",
    "```bash\n",
    "python monitoring/monitoring.py\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "> ğŸ–¥ï¸ **OUTPUT DELL'ESECUZIONE**\n",
    "> \n",
    "> ```\n",
    "> ğŸ“¥ Caricamento dataset TweetEval...\n",
    "> ğŸš€ Avvio monitoraggio del modello...\n",
    "> ğŸ“Š Valutazione su 1200 campioni...\n",
    ">    Processati 100/1200 campioni...\n",
    ">    Processati 200/1200 campioni...\n",
    ">    Processati 300/1200 campioni...\n",
    ">    ...\n",
    ">    Processati 1200/1200 campioni...\n",
    "> \n",
    "> ============================================================\n",
    "> ğŸ“Š RISULTATI DEL MONITORAGGIO\n",
    "> ============================================================\n",
    "> Accuracy:  0.8420\n",
    "> Precision: 0.8385\n",
    "> Recall:    0.8420\n",
    "> F1-Score:  0.8391\n",
    "> ============================================================\n",
    "> \n",
    "> âœ… Report salvati in: monitoring/reports\n",
    "> ```\n",
    "\n",
    "<br>\n",
    "\n",
    "### ğŸ“‚ Dove Trovare i Report\n",
    "\n",
    "I report vengono salvati nella cartella:\n",
    "\n",
    "> ğŸ“ **STRUTTURA CARTELLA REPORTS**\n",
    "> \n",
    "> ```\n",
    "> monitoring/reports/\n",
    "> â”œâ”€â”€ metrics_20260222_143527.csv\n",
    "> â”œâ”€â”€ confusion_matrix_20260222_143527.png\n",
    "> â”œâ”€â”€ predictions_20260222_143527.csv\n",
    "> â””â”€â”€ classification_report_20260222_143527.txt\n",
    "> ```\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ Integrazione con CI/CD\n",
    "\n",
    "Il monitoring Ã¨ giÃ  integrato nella pipeline CI/CD (vedi **STEP 7**):\n",
    "\n",
    "- **Job**: `model-validation`\n",
    "- **Trigger**: Automatico ad ogni push su `main` (dopo che i test passano)\n",
    "- **Artifacts**: Report salvati per **30 giorni** su GitHub Actions\n",
    "- **Download**: GitHub â†’ Actions â†’ Workflow run â†’ Artifacts section\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ“ **File di riferimento**: [monitoring/monitoring.py](monitoring/monitoring.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be61cae",
   "metadata": {},
   "source": [
    "# ğŸ“ Conclusioni\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š Riepilogo del Progetto\n",
    "\n",
    "Questo progetto ha implementato una **soluzione MLOps end-to-end** per l'analisi del sentiment sui social media, finalizzata al monitoraggio della reputazione online di **MachineInnovators Inc.**\n",
    "\n",
    "### ğŸ”§ Componenti Chiave Implementati\n",
    "\n",
    "**1ï¸âƒ£ Modello di Machine Learning**\n",
    "- **RoBERTa** pre-addestrato (`cardiffnlp/twitter-roberta-base-sentiment-latest`)\n",
    "- Classificazione in 3 sentiment: Positive, Negative, Neutral\n",
    "- Accuracy target: ~85-90% su testi in inglese\n",
    "\n",
    "**2ï¸âƒ£ API REST con FastAPI**\n",
    "- Endpoint per inferenza singola e batch processing\n",
    "- Validazione automatica degli input con Pydantic\n",
    "- Documentazione interattiva Swagger\n",
    "\n",
    "**3ï¸âƒ£ Testing Automatizzato**\n",
    "- Suite completa di test con pytest\n",
    "- Test del modello e test dell'API\n",
    "- Coverage report per monitorare la qualitÃ  del codice\n",
    "\n",
    "**4ï¸âƒ£ Containerizzazione Docker**\n",
    "- Immagine Docker ottimizzata\n",
    "- Ambiente isolato e riproducibile\n",
    "- Pubblicazione su Docker Hub (opzionale, manuale)\n",
    "\n",
    "**5ï¸âƒ£ CI/CD Pipeline**\n",
    "- 3 job automatizzati: test, model-validation, deploy\n",
    "- Testing automatico ad ogni push\n",
    "- Deployment automatico su HuggingFace Spaces\n",
    "\n",
    "**6ï¸âƒ£ Model Monitoring**\n",
    "- Script di validazione con dataset TweetEval (1200 campioni)\n",
    "- 4 tipologie di report (metriche, confusion matrix, predictions, classification report)\n",
    "- Alert system per accuracy < 70%\n",
    "- Report salvati come artifacts su GitHub Actions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
