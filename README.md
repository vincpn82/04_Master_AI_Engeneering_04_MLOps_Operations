# ğŸ¢ MachineInnovators - Sentiment Analysis MLOps

## ğŸ“Š Monitoraggio della Reputazione Online

![MLOps](https://img.shields.io/badge/MLOps-Sentiment%20Analysis-blue)
![Python](https://img.shields.io/badge/Python-3.10+-green)
![FastAPI](https://img.shields.io/badge/FastAPI-Framework-teal)
![HuggingFace](https://img.shields.io/badge/HuggingFace-Transformers-yellow)

Soluzione end-to-end di MLOps per l'analisi del sentiment sui social media, finalizzata al monitoraggio della reputazione online di **MachineInnovators Inc.**

Repository GitHub: https://github.com/vincpn82/04_Master_AI_Engeneering_04_MLOps_Operations.git

---

## ğŸ¯ Obiettivi del Progetto

- **Automazione dell'Analisi del Sentiment**: Classificazione automatica dei sentiment in positivo, neutrale o negativo  
- **Monitoraggio Continuo**: Sistema di monitoraggio continuo per valutare l'andamento del sentiment nel tempo
- **Pipeline CI/CD Automatizzata**: Testing e deployment automatico
- **Retraining del Modello**: Sistema per mantenere alta l'accuratezza predittiva del modello

---

## ğŸš€ Caratteristiche Principali

- âœ… **API RESTful con FastAPI**: Endpoint per inferenza in tempo reale e batch processing
- âœ… **Modello Pre-addestrato**: Utilizzo di `cardiffnlp/twitter-roberta-base-sentiment-latest`
- âœ… **Interfaccia Gradio**: Interfaccia web interattiva deployata su HuggingFace Spaces
- âœ… **Containerizzazione Docker**: Ambiente isolato e riproducibile
- âœ… **CI/CD con GitHub Actions**: Pipeline automatizzata per testing e deployment
- âœ… **Monitoraggio Continuo**: Valutazione automatica delle performance del modello

---

## ğŸ“‚ Struttura del Progetto

```
sentiment-analysis-mlops/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci-cd.yml              # Pipeline CI/CD principale
â”‚       â””â”€â”€ monitoring.yml         # Monitoraggio automatico
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # Applicazione FastAPI
â”‚   â”œâ”€â”€ model.py                   # Logica del modello
â”‚   â””â”€â”€ schema.py                  # Schemi Pydantic
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_model.py              # Test del modello
â”‚   â””â”€â”€ test_api.py                # Test dell'API
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ monitoring.py              # Script monitoraggio
â”‚   â””â”€â”€ reports/                   # Report generati
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_data.json           # Dati di esempio
â”œâ”€â”€ hf_spaces/                     # ğŸš€ HuggingFace Spaces deployment
â”‚   â”œâ”€â”€ README.md                  # Card con metadata YAML per Gradio
â”‚   â”œâ”€â”€ app.py                     # App Gradio (importa da ../app/)
â”‚   â””â”€â”€ requirements.txt           # Dipendenze minimal per HF Spaces
â”œâ”€â”€ Dockerfile                     # Container configuration
â”œâ”€â”€ .dockerignore                  # File esclusi dal container
â”œâ”€â”€ requirements.txt               # Dipendenze Python complete
â”œâ”€â”€ app.py                         # App Gradio locale (test)
â”œâ”€â”€ .gitignore                     # File esclusi da Git
â””â”€â”€ README.md                      # Documentazione completa
```

---

## ğŸ› ï¸ Installazione e Utilizzo

### Prerequisiti

- Python 3.10+
- Docker (opzionale)
- Git

### Setup Locale

```bash
# Clone il repository
git clone https://github.com/vincpn82/AI_Engeneering_04_MLOps_Operations.git
cd sentiment-analysis-mlops

# Crea ambiente virtuale
python -m venv venv
source:
 - unix: venv/bin/activate  
 - Windows: venv\Scripts\activate

# Installa le dipendenze
pip install -r requirements.txt
```

### Avvio dell'API

```bash
# Avvio con uvicorn
uvicorn app.main:app --reload

# Oppure con Docker
docker build -t sentiment-api .
docker run -p 8000:8000 sentiment-api
```

L'API sarÃ  disponibile su `http://localhost:8000`

- ğŸ“ Documentazione interattiva (Swagger): `http://localhost:8000/docs`  
- ğŸ“š Documentazione alternativa (ReDoc): `http://localhost:8000/redoc`

---

## ğŸ”Œ API Endpoints

### 1. Health Check

```bash
GET /health
```

### 2. Predizione Singola

```bash
POST /predict
Content-Type: application/json

{
  "text": "I love this product!"
}
```

**Response:**
```json
{
  "text": "I love this product!",
  "sentiment": "positive",
  "confidence": 0.99
}
```

### 3. Predizione Batch

```bash
POST /predict/batch
Content-Type: application/json

{
  "texts": [
    "Great service!",
    "Not satisfied.",
    "It's okay."
  ]
}
```

**Response:**
```json
{
  "results": [
    {"text": "Great service!", "sentiment": "positive", "confidence": 0.99},
    {"text": "Not satisfied.", "sentiment": "negative", "confidence": 0.97},
    {"text": "It's okay.", "sentiment": "neutral", "confidence": 0.85}
  ],
  "total": 3
}
```

---

## ğŸ§ª Testing

```bash
# Esegui tutti i test
pytest tests/ -v

# Test del modello
pytest tests/test_model.py -v

# Test dell'API
pytest tests/test_api.py -v

# Test con coverage
pytest tests/ --cov=app --cov-report=html
```

---

## ğŸ“Š Monitoraggio

Il sistema di monitoraggio valuta automaticamente le performance del modello:

```bash
# Esegui il monitoraggio manualmente
python monitoring/monitoring.py
```

I report vengono salvati in `monitoring/reports/` e includono:

- âœ… Metriche di performance (accuracy, precision, recall, F1-score)
- âœ… Matrice di confusione
- âœ… Report di classificazione dettagliato
- âœ… Predizioni complete per analisi

---

## ğŸ¨ Interfaccia Gradio su HuggingFace Spaces

Il progetto include un'interfaccia web interattiva costruita con Gradio e deployata automaticamente su HuggingFace Spaces.

### Caratteristiche dell'Interfaccia

- ğŸ¯ **Analisi in Tempo Reale**: Inserisci un testo e ottieni immediatamente il sentiment
- ğŸ“ **Esempi Pre-caricati**: Esempi di testi per testare rapidamente il modello
- ğŸ˜Š **Risultati Visualizzati**: Sentiment mostrato con emoji e percentuale di confidenza
- ğŸ¨ **Design Moderno**: Tema Soft di Gradio per un'esperienza utente ottimale

### Esecuzione Locale dell'App Gradio

```bash
# Avvia l'interfaccia Gradio
python app.py
```

L'interfaccia sarÃ  disponibile su `http://localhost:7860`

### Deploy Automatico

Ad ogni push sul branch `main`, la pipeline CI/CD:
1. Esegue tutti i test
2. Valida le performance del modello
3. Effettua il push automatico su HuggingFace Spaces
4. L'app Gradio viene automaticamente deployata e resa pubblica

---

## ğŸ³ Docker

### Build dell'immagine

```bash
docker build -t sentiment-analysis .
```

### Run del container

```bash
docker run -p 8000:8000 sentiment-analysis
```

---

## ğŸ”„ CI/CD Pipeline

Le GitHub Actions automatizzano:

1. **Testing**: Esecuzione automatica dei test ad ogni push
2. **Build & Push**: Creazione e pubblicazione dell'immagine Docker (solo su branch `main`)
3. **Deploy**: Deploy automatico su HuggingFace Spaces
4. **Monitoring**: Valutazione giornaliera delle performance del modello (schedulata alle 02:00 UTC)

### Secrets necessari

- `HF_TOKEN`: Token HuggingFace
- `HF_SPACE_NAME`: Nome dello Space HuggingFace

---

## ğŸ“ˆ Metriche e Performance

Il modello viene valutato su:

- **Accuracy**: Precisione complessiva
- **Precision**: Precisione per classe
- **Recall**: Richiamo per classe
- **F1-Score**: Media armonica di precision e recall

**Soglia di alert**: Accuracy < 0.69